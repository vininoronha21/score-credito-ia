# ğŸ¦ Credit Scoring System with Machine Learning

End-to-end Machine Learning pipeline for Credit Scoring, covering data generation through executive-level visualization in Power BI, with a focus on risk-driven decision making.

## ğŸ“Š Overview

This project implements a default prediction system using Machine Learning, simulating a realistic credit scenario with synthetic data and consistent business logic.

The pipeline encompasses:

* Generation of 100,000 synthetic records with risk and protective factors
* Exploratory Data Analysis (EDA)
* Training and comparison of supervised learning models
* Threshold analysis and business trade-offs
* Artifact export for Power BI visualization

## ğŸ¯ Objectives

**Initial screening model** for credit scoring, optimized to **maximize recall** (detect defaulters).

**Practical application:** Clients classified as high-risk are routed to detailed manual analysis, while low-risk clients proceed through automated workflow.

## ğŸ–¥ï¸ Dashboard

<img src="assets/dashboard_rf.jpeg" width="1000">

## ğŸ“ˆ Model Performance

### Logistic Regression (Selected Model)

> Metrics considering recall-optimized threshold

| Metric              | Value  | Interpretation                         |
| ------------------- | ------ | -------------------------------------- |
| **Recall**    | 66.95% | Detects ~2 out of every 3 defaulters   |
| **AUC-ROC**   | 0.667  | Moderate discriminative power          |
| **Precision** | 27.65% | Screening model (high recall priority) |
| **Accuracy**  | 60.01% | Overall accuracy                       |

<img src="assets/03_screenshots/img11.png" width="1000">

### Model Comparison (Default Threshold = 0.5)

| Model                         | AUC-ROC | Recall | Precision |
| ----------------------------- | ------- | ------ | --------- |
| **Logistic Regression** | 0.775   | 15.7%  | 57.3%     |
| **Random Forest**       | 0.856   | 77.8%  | 43.5%     |

<img src="assets/03_screenshots/img12.png" width="1000">

**Decision rationale:** Despite Random Forest achieving superior metrics in some scenarios, Logistic Regression was prioritized for:

* Model interpretability
* Prediction stability
* Compliance and auditability
* Lower computational overhead
* Better fit for regulated credit environments

## ğŸ”¬ Key Insights

<img src="assets/02_screenshots/img9.png" width="600">

### Top 3 Most Important Features

1. **Payment Delay History** â€” 50.6%
2. **Employment Status** â€” 23.1%
3. **Number of Dependents** â€” 15.7%

### Highest Risk Profiles

* **Unemployed:** ~64% default rate
* **Credit Score < 500:** ~37% default rate
* **Annual Income < R$ 30k:** ~29% default rate

### Feature Engineering

* Income Per Capita: Engineered to better capture actual financial capacity

`income_per_capita = annual_income / (num_dependents + 1)` â€” captures household financial context more effectively than gross income.

## ğŸ“ Project Structure

```
score-credito-ia/
â”‚
â”œâ”€â”€ assets/                              # Visual resources
â”‚
â”œâ”€â”€ data/                                # Raw data
â”‚   â”œâ”€â”€ database.db                      # SQLite database
â”‚   â””â”€â”€ clientes_backup.csv              # CSV backup
â”‚
â”œâ”€â”€ insights/                            # Analysis outputs
â”‚   â”œâ”€â”€ feature_importance.csv           # Feature importance rankings
â”‚   â”œâ”€â”€ insights_eda.txt                 # EDA summary
â”‚   â””â”€â”€ matriz_correlacao.csv            # Correlation matrix
â”‚
â”œâ”€â”€ models/                              # Trained artifacts
â”‚   â”œâ”€â”€ encoder_escolaridade.pkl
â”‚   â”œâ”€â”€ encoder_estado.pkl
â”‚   â”œâ”€â”€ encoder_estado_civil.pkl
â”‚   â”œâ”€â”€ encoder_genero.pkl
â”‚   â”œâ”€â”€ encoder_ocupacao.pkl
â”‚   â”œâ”€â”€ metadados_modelo.json            # Model metadata
â”‚   â”œâ”€â”€ modelo_final.pkl                 # Logistic Regression model
â”‚   â””â”€â”€ scaler.pkl                       # StandardScaler
â”‚
â”œâ”€â”€ notebooks/                           # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_criar_database.ipynb          # Synthetic data generation
â”‚   â”œâ”€â”€ 02_analise_exploratoria.ipynb    # EDA and correlations
â”‚   â”œâ”€â”€ 03_modelagem_ml.ipynb            # Model training and validation
â”‚   â””â”€â”€ 04_exportar_powerbi.ipynb        # Power BI export pipeline
â”‚
â”œâ”€â”€ powerbi/                             # Visualization datasets
â”‚   â”œâ”€â”€ confusion_matrix.csv
â”‚   â”œâ”€â”€ dataset_powerbi.csv              # Main dataset (100k rows)
â”‚   â”œâ”€â”€ feature_importance_comparison.csv
â”‚   â”œâ”€â”€ inadimplencia_ocupacao.csv
â”‚   â”œâ”€â”€ inadimplencia_renda.csv
â”‚   â”œâ”€â”€ inadimplencia_score.csv
â”‚   â”œâ”€â”€ model_comparison.csv             # LR vs RF comparison
â”‚   â”œâ”€â”€ precision_recall_curve.csv
â”‚   â”œâ”€â”€ roc_curve.csv
â”‚   â””â”€â”€ threshold_analysis.csv           # Threshold analysis
â”‚
â”œâ”€â”€ .gitignore                           # Git ignore rules
â”œâ”€â”€ LICENSE                              # Project license
â”œâ”€â”€ README.md                            # Documentation (PT-BR)
â”œâ”€â”€ README-EN.md                         # Documentation (EN-US)
â”œâ”€â”€ ROADMAP.md                           # Future roadmap
â””â”€â”€ requirements.txt                     # Python dependencies
```

## ğŸ› ï¸ Tech Stack

* **Python 3.12+**
* **Pandas**
* **NumPy**
* **Scikit-learn**
* **SQLite**
* **Power BI**

## ğŸš€ Getting Started

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run Notebooks (in order)

```bash
# 1. Generate 100k synthetic records
jupyter notebook notebooks/01_criar_database.ipynb

# 2. Exploratory Data Analysis
jupyter notebook notebooks/02_analise_exploratoria.ipynb

# 3. Model training
jupyter notebook notebooks/03_modelagem_ml.ipynb

# 4. Export to Power BI
jupyter notebook notebooks/04_exportar_powerbi.ipynb
```

### 3. Power BI Dashboard

Open Power BI Desktop and import CSVs from `powerbi/` folder:

1. **Get Data** â†’ **Text/CSV**
2. Import all 10 CSV files
3. Create visualizations following the guide below

## ğŸ“Š Power BI Dashboard Guide

> The dashboard enables both executive and operational analysis:

### Page 1: Executive Overview

* **KPI Cards:** Default rate, Recall, AUC-ROC, Total clients
* **Chart:** Threshold vs Precision/Recall (dual-line)
* **Slicer:** Interactive threshold (0.3, 0.4, 0.5, 0.6, 0.7)

### Page 2: Model Performance

* **ROC Curve** (LR vs RF comparison)
* **Confusion Matrix** (threshold-filtered)
* **Comparison Table** (LR vs RF)

### Page 3: Feature Importance

* **Bar Chart:** Top 10 most important features
* **Cards:** Top 3 features highlighted

### Page 4: Business Analysis

* **Chart:** Default rate by Employment Status
* **Chart:** Default rate by Credit Score Range
* **Chart:** Default rate by Income Range

### Page 5: Individual Drill-Down

* **Table:** Clients with default probability
* **Filters:** State, Employment, Age, Income
* **Scatter Plot:** Income vs Score (color-coded by default)

## ğŸ“ Methodology

### 1. Data Generation

* 100,000 synthetic clients
* 16 explanatory variables
* Target generated with realistic business logic

### 2. Exploratory Analysis

* Descriptive statistics
* Correlation analysis
* Risk and protective factors identification

### 3. Modeling

* Train/Test split: 70/30
* Categorical encoding and normalization
* 5-fold cross-validation
* Threshold analysis (17 thresholds tested)
* Model comparison: Logistic Regression vs Random Forest

### 4. Export

* Power BI-ready datasets
* No additional processing required

## ğŸ“‹ Trade-offs and Business Decisions

### Why Prioritize Recall?

âœ… False Negative cost â‰ˆ **R$ 5,000** (~USD 1,000)

âœ… False Positive cost â‰ˆ **R$ 1,000** (~USD 200)

âœ… False positives can be mitigated through manual review

### Why Logistic Regression?

âœ… **Interpretable** â€” Coefficients = Business rules

âœ… **Fast** â€” Inference latency < 10ms

âœ… **Auditable** â€” Easy to explain for compliance

âœ… **Performance** â€” Meets recall >65% requirement with threshold tuning

### Threshold Trade-off Analysis

| Threshold | Profile      | Precision | Recall |
| --------- | ------------ | --------- | ------ |
| 0.30      | Aggressive   | 44.7%     | 48.8%  |
| 0.50      | Balanced     | 57.3%     | 15.7%  |
| 0.70      | Conservative | 62.7%     | 2.6%   |

<img src="assets/03_screenshots/img13.png" width="1000">

## ğŸ”„ Roadmap

* [ ] REST API deployment (FastAPI)
* [ ] Data drift monitoring
* [ ] Automated retraining pipeline
* [ ] A/B testing framework for thresholds
* [ ] CRM system integration

## âš ï¸ Disclaimer

This project was developed with focus on study and practical application of Machine Learning in Credit Scoring, using synthetic data and realistic business assumptions.

While following best practices in modeling, evaluation, and decision-making, this is an educational/portfolio project and does not represent a production-grade credit system. Some simplifications were intentionally adopted for didactic and learning purposes.

The primary objective is to demonstrate:

- ML pipeline structuring
- Risk-oriented analysis
- Trade-off based decision making
- Technical and business communication

## ğŸ“ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

Developed by **VinÃ­cius Forte**

- ğŸ™ GitHub: [vininoronha21](https://github.com/vininoronha21)
- ğŸ’¼ LinkedIn: [VinÃ­cius Noronha](https://linkedin.com/in/viniciusnoronha)
- ğŸ“§ Email: contatovininoronha@gmail.com

---

**Note:** For the Portuguese version, see [README.md](README.md)
