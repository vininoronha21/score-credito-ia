{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412fdae2",
   "metadata": {},
   "source": [
    "# üìä EXPORTA√á√ÉO DE DADOS PARA POWER BI\n",
    "\n",
    "**Objetivo:** Preparar e gerar todos os datasets necess√°rios para cria√ß√£o de dashboards de an√°lise de cr√©dito no Power BI.\n",
    "\n",
    "### ‚è≥ Arquivos gerados\n",
    "- dataset_powerbi.csv ‚Äì dataset principal com probabilidades e previs√µes\n",
    "- threshold_analysis.csv ‚Äì m√©tricas para diferentes thresholds\n",
    "- roc_curve.csv ‚Äì dados para curva ROC de cada modelo\n",
    "- precision_recall_curve.csv ‚Äì dados para curva Precision-Recall\n",
    "- feature_importance_comparison.csv ‚Äì import√¢ncia das features comparando LR e RF\n",
    "- confusion_matrix.csv ‚Äì matrizes de confus√£o por threshold\n",
    "- model_comparison.csv ‚Äì compara√ß√£o de m√©tricas entre modelos\n",
    "- inadimplencia_ocupacao.csv ‚Äì taxa de inadimpl√™ncia por ocupa√ß√£o\n",
    "- inadimplencia_score.csv ‚Äì taxa de inadimpl√™ncia por faixa de score\n",
    "- inadimplencia_renda.csv ‚Äì taxa de inadimpl√™ncia por faixa de renda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c661c",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚≠ê MODELAGEM e AVALIA√á√ÉO DE MODELOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca87757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 1. IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Criar pasta de destino\n",
    "os.makedirs('../powerbi', exist_ok=True)\n",
    "\n",
    "print(\"üìä INICIANDO EXPORTA√á√ÉO...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d880be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 2. CARREGANDO DADOS DO SQLITE\n",
    "conn = sqlite3.connect('../data/database.db')\n",
    "df = pd.read_sql(\"SELECT * FROM clientes\", conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"‚úì Dados carregados: {len(df):,} registros\")\n",
    "\n",
    "# Criar feature renda_per_capita\n",
    "df['renda_per_capita'] = df['renda_anual'] / (df['numero_dependentes'] + 1)\n",
    "print(f\"‚úì Feature 'renda_per_capita' criada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac517e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 3. PREPARANDO DADOS PARA MODELAGEM\n",
    "target = 'inadimplente'\n",
    "features = [col for col in df.columns if col not in ['inadimplente', 'id_cliente']]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target]\n",
    "\n",
    "# Split treino/teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"‚úì Split: {len(X_train):,} treino / {len(X_test):,} teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1360b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 4. ENCODING DE VARI√ÅVEIS CATEG√ìRICAS\n",
    "cat_cols = X.select_dtypes(include='object').columns\n",
    "encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "  le = LabelEncoder()\n",
    "  X_train[col] = le.fit_transform(X_train[col])\n",
    "  X_test[col] = le.transform(X_test[col])\n",
    "  encoders[col] = le\n",
    "\n",
    "print(f\"‚úì Encoding aplicado em {len(cat_cols)} colunas\")\n",
    "\n",
    "# Normaliza√ß√£o\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"‚úì Normaliza√ß√£o aplicada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d963655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 5. TREINAR LR (LOGISTIC REGRESSION)\n",
    "print(\"\\nüéØ Treinando Logistic Regression...\")\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_proba_lr = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "print(f\"  AUC: {roc_auc_score(y_test, y_proba_lr):.4f}\")\n",
    "print(f\"  Recall: {recall_score(y_test, y_pred_lr):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 6. TREINANDO RF (RANDOM FOREST)\n",
    "print(\"\\nüå≤ Treinando Random Forest...\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_proba_rf = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_proba_rf):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_rf):.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06dca5",
   "metadata": {},
   "source": [
    "---\n",
    "# üì¶ EXPORTAR DATASETS PARA POWER BI\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d910c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 7. DATASET PRINCIPAL\n",
    "print(\"üì¶ EXPORTANDO DATASETS PARA ../powerbi/\")\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ Dataset principal\")\n",
    "df_export = df.copy()\n",
    "df_export['probabilidade_lr'] = np.nan\n",
    "df_export['probabilidade_rf'] = np.nan\n",
    "df_export['predicao_lr_50'] = np.nan\n",
    "df_export['predicao_rf_50'] = np.nan\n",
    "df_export['conjunto'] = 'treino'\n",
    "\n",
    "test_indices = X_test.index\n",
    "df_export.loc[test_indices, 'probabilidade_lr'] = y_proba_lr\n",
    "df_export.loc[test_indices, 'probabilidade_rf'] = y_proba_rf\n",
    "df_export.loc[test_indices, 'predicao_lr_50'] = (y_proba_lr >= 0.5).astype(int)\n",
    "df_export.loc[test_indices, 'predicao_rf_50'] = (y_proba_rf >= 0.5).astype(int)\n",
    "df_export.loc[test_indices, 'conjunto'] = 'teste'\n",
    "\n",
    "df_export.to_csv('../powerbi/dataset_powerbi.csv', index=False)\n",
    "print(f\"‚úì dataset_powerbi.csv ({len(df_export):,} registros)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 8. AN√ÅLISE DE THRESHOLD\n",
    "print(\"2Ô∏è‚É£ An√°lise de threshold\")\n",
    "threshold_data = []\n",
    "\n",
    "for t in np.arange(0.1, 0.95, 0.05):\n",
    "  y_pred = (y_proba_lr >= t).astype(int)\n",
    "  threshold_data.append({\n",
    "    'threshold': t,\n",
    "    'precision': precision_score(y_test, y_pred),\n",
    "    'recall': recall_score(y_test, y_pred),\n",
    "    'f1_score': f1_score(y_test, y_pred),\n",
    "    'accuracy': accuracy_score(y_test, y_pred)\n",
    "  })\n",
    "\n",
    "df_threshold = pd.DataFrame(threshold_data)\n",
    "df_threshold.to_csv('../powerbi/threshold_analysis.csv', index=False)\n",
    "print(f\"‚úì threshold_analysis.csv ({len(df_threshold)} thresholds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 9. CURVA ROC\n",
    "print(\"3Ô∏è‚É£ Curva ROC\")\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_proba_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)\n",
    "roc_data = []\n",
    "\n",
    "for i in range(len(fpr_lr)):\n",
    "  roc_data.append({'modelo': 'Logistic Regression', 'fpr': fpr_lr[i], 'tpr': tpr_lr[i]})\n",
    "for i in range(len(fpr_rf)):\n",
    "  roc_data.append({'modelo': 'Random Forest', 'fpr': fpr_rf[i], 'tpr': tpr_rf[i]})\n",
    "\n",
    "df_roc = pd.DataFrame(roc_data)\n",
    "df_roc.to_csv('../powerbi/roc_curve.csv', index=False)\n",
    "print(f\"‚úì roc_curve.csv ({len(df_roc)} pontos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac032d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 10. PRECISION-RECALL CURVE\n",
    "print(\"4Ô∏è‚É£ PRC\")\n",
    "precision_lr, recall_lr, _ = precision_recall_curve(y_test, y_proba_lr)\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_proba_rf)\n",
    "pr_data = []\n",
    "\n",
    "for i in range(len(precision_lr)):\n",
    "  pr_data.append({'modelo': 'Logistic Regression', 'precision': precision_lr[i], 'recall': recall_lr[i]})\n",
    "for i in range(len(precision_rf)):\n",
    "  pr_data.append({'modelo': 'Random Forest', 'precision': precision_rf[i], 'recall': recall_rf[i]})\n",
    "\n",
    "df_pr = pd.DataFrame(pr_data)\n",
    "df_pr.to_csv('../powerbi/precision_recall_curve.csv', index=False)\n",
    "print(f\"‚úì precision_recall_curve.csv ({len(df_pr)} pontos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 11. FEATURE IMPORTANCE\n",
    "print(\"\\n5Ô∏è‚É£ Feature Importance\")\n",
    "feature_names = X_train.columns\n",
    "\n",
    "df_importance = pd.DataFrame({\n",
    "  'feature': feature_names,\n",
    "  'importance_lr': np.abs(lr.coef_[0]),\n",
    "  'importance_rf': rf.feature_importances_,\n",
    "  'coefficient_lr': lr.coef_[0]\n",
    "}).sort_values('importance_lr', ascending=False)\n",
    "\n",
    "df_importance.to_csv('../powerbi/feature_importance_comparison.csv', index=False)\n",
    "print(f\"‚úì feature_importance_comparison.csv ({len(df_importance)} features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 12. MATRIZ DE CONFUS√ÉO\n",
    "print(\"6Ô∏è‚É£ Matrizes de confus√£o\")\n",
    "conf_data = []\n",
    "thresholds_conf = [0.30, 0.40, 0.50, 0.60, 0.70]\n",
    "\n",
    "for t in thresholds_conf:\n",
    "  y_pred = (y_proba_lr >= t).astype(int)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "  conf_data.append({'threshold': t, 'categoria': 'TN (Verdadeiro Negativo)', 'valor': cm[0,0], 'percentual': cm[0,0] / cm.sum()})\n",
    "  conf_data.append({'threshold': t, 'categoria': 'FP (Falso Positivo)', 'valor': cm[0,1], 'percentual': cm[0,1] / cm.sum()})\n",
    "  conf_data.append({'threshold': t, 'categoria': 'FN (Falso Negativo)', 'valor': cm[1,0], 'percentual': cm[1,0] / cm.sum()})\n",
    "  conf_data.append({'threshold': t, 'categoria': 'TP (Verdadeiro Positivo)', 'valor': cm[1,1], 'percentual': cm[1,1] / cm.sum()})\n",
    "\n",
    "df_confusion = pd.DataFrame(conf_data)\n",
    "df_confusion.to_csv('../powerbi/confusion_matrix.csv', index=False)\n",
    "print(f\"‚úì confusion_matrix.csv ({len(df_confusion)} registros)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 13. COMPARA√á√ÉO DE MODELOS\n",
    "print(\"7Ô∏è‚É£ Compara√ß√£o LR vs RF\")\n",
    "modelo_comp = []\n",
    "\n",
    "for threshold in [0.30, 0.40, 0.50, 0.60]:\n",
    "  y_pred_lr = (y_proba_lr >= threshold).astype(int)\n",
    "  y_pred_rf = (y_proba_rf >= threshold).astype(int)\n",
    "    \n",
    "  modelo_comp.append({\n",
    "      'modelo': 'Logistic Regression',\n",
    "      'threshold': threshold,\n",
    "      'accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "      'precision': precision_score(y_test, y_pred_lr),\n",
    "      'recall': recall_score(y_test, y_pred_lr),\n",
    "      'f1_score': f1_score(y_test, y_pred_lr),\n",
    "      'auc_roc': roc_auc_score(y_test, y_proba_lr)\n",
    "  })\n",
    "    \n",
    "  modelo_comp.append({\n",
    "      'modelo': 'Random Forest',\n",
    "      'threshold': threshold,\n",
    "      'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "      'precision': precision_score(y_test, y_pred_rf),\n",
    "      'recall': recall_score(y_test, y_pred_rf),\n",
    "      'f1_score': f1_score(y_test, y_pred_rf),\n",
    "      'auc_roc': roc_auc_score(y_test, y_proba_rf)\n",
    "  })\n",
    "\n",
    "df_modelo_comp = pd.DataFrame(modelo_comp)\n",
    "df_modelo_comp.to_csv('../powerbi/model_comparison.csv', index=False)\n",
    "print(f\"‚úì model_comparison.csv ({len(df_modelo_comp)} registros)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√âLULA 14. ESTAT√çSTICAS POR GRUPO\n",
    "print(\"8Ô∏è‚É£ Estat√≠sticas por grupo...\")\n",
    "\n",
    "# Inadimpl√™ncia por ocupa√ß√£o\n",
    "inad_ocupacao = df.groupby('ocupacao')['inadimplente'].agg(['mean', 'count']).reset_index()\n",
    "inad_ocupacao.columns = ['ocupacao', 'taxa_inadimplencia', 'total']\n",
    "inad_ocupacao.to_csv('../powerbi/inadimplencia_ocupacao.csv', index=False)\n",
    "\n",
    "# Inadimpl√™ncia por score serasa\n",
    "df['faixa_score'] = pd.cut(df['score_serasa_externo'], \n",
    "                            bins=[0, 400, 500, 600, 700, 1000],\n",
    "                            labels=['0-400', '400-500', '500-600', '600-700', '700+'])\n",
    "inad_score = df.groupby('faixa_score', observed=True)['inadimplente'].agg(['mean', 'count']).reset_index()\n",
    "inad_score.columns = ['faixa_score', 'taxa_inadimplencia', 'total']\n",
    "inad_score.to_csv('../powerbi/inadimplencia_score.csv', index=False)\n",
    "\n",
    "# Inadimpl√™ncia por faixa de renda\n",
    "df['faixa_renda'] = pd.cut(df['renda_anual'], \n",
    "                            bins=[0, 30000, 60000, 100000, 1000000],\n",
    "                            labels=['<30k', '30-60k', '60-100k', '>100k'])\n",
    "inad_renda = df.groupby('faixa_renda', observed=True)['inadimplente'].agg(['mean', 'count']).reset_index()\n",
    "inad_renda.columns = ['faixa_renda', 'taxa_inadimplencia', 'total']\n",
    "inad_renda.to_csv('../powerbi/inadimplencia_renda.csv', index=False)\n",
    "\n",
    "print(f\"‚úì inadimplencia_ocupacao.csv\")\n",
    "print(f\"‚úì inadimplencia_score.csv\")\n",
    "print(f\"‚úì inadimplencia_renda.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2efd805",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚úÖ EXPORTA√á√ÉO CONCLU√çDA COM SUCESSO!\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e265de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos criados em ../powerbi/:\n",
      "1. dataset_powerbi.csv\n",
      "2. threshold_analysis.csv\n",
      "3. roc_curve.csv\n",
      "4. precision_recall_curve.csv\n",
      "5. feature_importance_comparison.csv\n",
      "6. confusion_matrix.csv\n",
      "7. model_comparison.csv\n",
      "8. inadimplencia_ocupacao.csv\n",
      "9. inadimplencia_score.csv\n",
      "10. inadimplencia_renda.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Arquivos criados em ../powerbi/:\")\n",
    "print(\"1. dataset_powerbi.csv\")\n",
    "print(\"2. threshold_analysis.csv\")\n",
    "print(\"3. roc_curve.csv\")\n",
    "print(\"4. precision_recall_curve.csv\")\n",
    "print(\"5. feature_importance_comparison.csv\")\n",
    "print(\"6. confusion_matrix.csv\")\n",
    "print(\"7. model_comparison.csv\")\n",
    "print(\"8. inadimplencia_ocupacao.csv\")\n",
    "print(\"9. inadimplencia_score.csv\")\n",
    "print(\"10. inadimplencia_renda.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
