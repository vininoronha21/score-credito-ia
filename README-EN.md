# üè¶ Credit Scoring System with Machine Learning

End-to-end Machine Learning pipeline for Credit Scoring, covering data generation through executive-level visualization in Power BI, with a focus on risk-driven decision making.

## üìä Overview

This project implements a default prediction system using Machine Learning, simulating a realistic credit scenario with synthetic data and consistent business logic.

The pipeline encompasses:

* Generation of 100,000 synthetic records with risk and protective factors
* Exploratory Data Analysis (EDA)
* Training and comparison of supervised learning models
* Threshold analysis and business trade-offs
* Artifact export for Power BI visualization

## üéØ Objectives

**Initial screening model** for credit scoring, optimized to **maximize recall** (detect defaulters).

**Practical application:** Clients classified as high-risk are routed to detailed manual analysis, while low-risk clients proceed through automated workflow.

## üìà Model Performance

### Logistic Regression (Selected Model)

> Metrics considering recall-optimized threshold

| Metric              | Value  | Interpretation                         |
| ------------------- | ------ | -------------------------------------- |
| **Recall**    | 66.95% | Detects ~2 out of every 3 defaulters   |
| **AUC-ROC**   | 0.667  | Moderate discriminative power          |
| **Precision** | 27.65% | Screening model (high recall priority) |
| **Accuracy**  | 60.01% | Overall accuracy                       |

### Model Comparison (Default Threshold = 0.5)

| Model                         | AUC-ROC | Recall | Precision |
| ----------------------------- | ------- | ------ | --------- |
| **Logistic Regression** | 0.775   | 15.7%  | 57.3%     |
| **Random Forest**       | 0.856   | 77.8%  | 43.5%     |

**Decision rationale:** Despite Random Forest achieving superior metrics in some scenarios, Logistic Regression was prioritized for:

* Model interpretability
* Prediction stability
* Compliance and auditability
* Lower computational overhead
* Better fit for regulated credit environments

## üî¨ Key Insights

### Top 3 Most Important Features

1. **Payment Delay History** ‚Äî 50.6%
2. **Employment Status** ‚Äî 23.1%
3. **Number of Dependents** ‚Äî 15.7%

### Highest Risk Profiles

* **Unemployed:** ~64% default rate
* **Credit Score < 500:** ~37% default rate
* **Annual Income < R$ 30k:** ~29% default rate

### Feature Engineering

* Income Per Capita: Engineered to better capture actual financial capacity

`income_per_capita = annual_income / (num_dependents + 1)` ‚Äî captures household financial context more effectively than gross income.

## üìÅ Project Structure

```
score-credito-ia/
‚îÇ
‚îú‚îÄ‚îÄ assets/                              # Visual resources
‚îÇ
‚îú‚îÄ‚îÄ data/                                # Raw data
‚îÇ   ‚îú‚îÄ‚îÄ database.db                      # SQLite database
‚îÇ   ‚îî‚îÄ‚îÄ clientes_backup.csv              # CSV backup
‚îÇ
‚îú‚îÄ‚îÄ insights/                            # Analysis outputs
‚îÇ   ‚îú‚îÄ‚îÄ feature_importance.csv           # Feature importance rankings
‚îÇ   ‚îú‚îÄ‚îÄ insights_eda.txt                 # EDA summary
‚îÇ   ‚îî‚îÄ‚îÄ matriz_correlacao.csv            # Correlation matrix
‚îÇ
‚îú‚îÄ‚îÄ models/                              # Trained artifacts
‚îÇ   ‚îú‚îÄ‚îÄ encoder_escolaridade.pkl
‚îÇ   ‚îú‚îÄ‚îÄ encoder_estado.pkl
‚îÇ   ‚îú‚îÄ‚îÄ encoder_estado_civil.pkl
‚îÇ   ‚îú‚îÄ‚îÄ encoder_genero.pkl
‚îÇ   ‚îú‚îÄ‚îÄ encoder_ocupacao.pkl
‚îÇ   ‚îú‚îÄ‚îÄ metadados_modelo.json            # Model metadata
‚îÇ   ‚îú‚îÄ‚îÄ modelo_final.pkl                 # Logistic Regression model
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl                       # StandardScaler
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                           # Jupyter Notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01_criar_database.ipynb          # Synthetic data generation
‚îÇ   ‚îú‚îÄ‚îÄ 02_analise_exploratoria.ipynb    # EDA and correlations
‚îÇ   ‚îú‚îÄ‚îÄ 03_modelagem_ml.ipynb            # Model training and validation
‚îÇ   ‚îî‚îÄ‚îÄ 04_exportar_powerbi.ipynb        # Power BI export pipeline
‚îÇ
‚îú‚îÄ‚îÄ powerbi/                             # Visualization datasets
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.csv
‚îÇ   ‚îú‚îÄ‚îÄ dataset_powerbi.csv              # Main dataset (100k rows)
‚îÇ   ‚îú‚îÄ‚îÄ feature_importance_comparison.csv
‚îÇ   ‚îú‚îÄ‚îÄ inadimplencia_ocupacao.csv
‚îÇ   ‚îú‚îÄ‚îÄ inadimplencia_renda.csv
‚îÇ   ‚îú‚îÄ‚îÄ inadimplencia_score.csv
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.csv             # LR vs RF comparison
‚îÇ   ‚îú‚îÄ‚îÄ precision_recall_curve.csv
‚îÇ   ‚îú‚îÄ‚îÄ roc_curve.csv
‚îÇ   ‚îî‚îÄ‚îÄ threshold_analysis.csv           # Threshold analysis
‚îÇ
‚îú‚îÄ‚îÄ .gitignore                           # Git ignore rules
‚îú‚îÄ‚îÄ LICENSE                              # Project license
‚îú‚îÄ‚îÄ README.md                            # Documentation (PT-BR)
‚îú‚îÄ‚îÄ README-EN.md                         # Documentation (EN-US)
‚îú‚îÄ‚îÄ ROADMAP.md                           # Future roadmap
‚îî‚îÄ‚îÄ requirements.txt                     # Python dependencies
```

## üõ†Ô∏è Tech Stack

* **Python 3.12+**
* **Pandas**
* **NumPy**
* **Scikit-learn**
* **SQLite**
* **Power BI**

## üöÄ Getting Started

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run Notebooks (in order)

```bash
# 1. Generate 100k synthetic records
jupyter notebook notebooks/01_criar_database.ipynb

# 2. Exploratory Data Analysis
jupyter notebook notebooks/02_analise_exploratoria.ipynb

# 3. Model training
jupyter notebook notebooks/03_modelagem_ml.ipynb

# 4. Export to Power BI
jupyter notebook notebooks/04_exportar_powerbi.ipynb
```

### 3. Power BI Dashboard

Open Power BI Desktop and import CSVs from `powerbi/` folder:

1. **Get Data** ‚Üí **Text/CSV**
2. Import all 10 CSV files
3. Create visualizations following the guide below

## üìä Power BI Dashboard Guide

> The dashboard enables both executive and operational analysis:

### Page 1: Executive Overview

* **KPI Cards:** Default rate, Recall, AUC-ROC, Total clients
* **Chart:** Threshold vs Precision/Recall (dual-line)
* **Slicer:** Interactive threshold (0.3, 0.4, 0.5, 0.6, 0.7)

### Page 2: Model Performance

* **ROC Curve** (LR vs RF comparison)
* **Confusion Matrix** (threshold-filtered)
* **Comparison Table** (LR vs RF)

### Page 3: Feature Importance

* **Bar Chart:** Top 10 most important features
* **Cards:** Top 3 features highlighted

### Page 4: Business Analysis

* **Chart:** Default rate by Employment Status
* **Chart:** Default rate by Credit Score Range
* **Chart:** Default rate by Income Range

### Page 5: Individual Drill-Down

* **Table:** Clients with default probability
* **Filters:** State, Employment, Age, Income
* **Scatter Plot:** Income vs Score (color-coded by default)

## üéì Methodology

### 1. Data Generation

* 100,000 synthetic clients
* 16 explanatory variables
* Target generated with realistic business logic

### 2. Exploratory Analysis

* Descriptive statistics
* Correlation analysis
* Risk and protective factors identification

### 3. Modeling

* Train/Test split: 70/30
* Categorical encoding and normalization
* 5-fold cross-validation
* Threshold analysis (17 thresholds tested)
* Model comparison: Logistic Regression vs Random Forest

### 4. Export

* Power BI-ready datasets
* No additional processing required

## üìã Trade-offs and Business Decisions

### Why Prioritize Recall?

‚úÖ False Negative cost ‚âà **R$ 5,000** (~USD 1,000)

‚úÖ False Positive cost ‚âà **R$ 1,000** (~USD 200)

‚úÖ False positives can be mitigated through manual review

### Why Logistic Regression?

‚úÖ **Interpretable** ‚Äî Coefficients = Business rules

‚úÖ **Fast** ‚Äî Inference latency < 10ms

‚úÖ **Auditable** ‚Äî Easy to explain for compliance

‚úÖ **Performance** ‚Äî Meets recall >65% requirement with threshold tuning

### Threshold Trade-off Analysis

| Threshold | Profile      | Precision | Recall |
| --------- | ------------ | --------- | ------ |
| 0.30      | Aggressive   | 44.7%     | 48.8%  |
| 0.50      | Balanced     | 57.3%     | 15.7%  |
| 0.70      | Conservative | 62.7%     | 2.6%   |

## üîÑ Roadmap

* [ ] REST API deployment (FastAPI)
* [ ] Data drift monitoring
* [ ] Automated retraining pipeline
* [ ] A/B testing framework for thresholds
* [ ] CRM system integration

## ‚ö†Ô∏è Disclaimer

This project was developed with focus on study and practical application of Machine Learning in Credit Scoring, using synthetic data and realistic business assumptions.

While following best practices in modeling, evaluation, and decision-making, this is an educational/portfolio project and does not represent a production-grade credit system. Some simplifications were intentionally adopted for didactic and learning purposes.

The primary objective is to demonstrate:

- ML pipeline structuring
- Risk-oriented analysis
- Trade-off based decision making
- Technical and business communication

## üìù License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## üë®‚Äçüíª Author

Developed by **Vin√≠cius Forte**

- üêô GitHub: [vininoronha21](https://github.com/vininoronha21)
- üíº LinkedIn: [Vin√≠cius Noronha](https://linkedin.com/in/viniciusnoronha)
- üìß Email: contatovininoronha@gmail.com

---

**Note:** For the Portuguese version, see [README.md](README.md)
