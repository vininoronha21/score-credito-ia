{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb4dc11",
   "metadata": {},
   "source": [
    "# ü§ñ MODELAGEM DE MACHINE LEARNING PARA SCORE DE CR√âDITO\n",
    "\n",
    "**Objetivo:** Desenvolver, avaliar e selecionar modelos de Machine Learning para prever a inadimpl√™ncia de clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c26107",
   "metadata": {},
   "source": [
    "### üìå Etapas\n",
    "- Reparar dados para Machine Learning\n",
    "- Codificar vari√°veis categ√≥ricas\n",
    "- Dividir em treino e teste\n",
    "- Treinar m√∫ltiplos modelos de classifica√ß√£o\n",
    "- Avaliar performance com m√©tricas adequadas\n",
    "- Selecionar melhor modelo\n",
    "- Analisar feature importance\n",
    "- Salvar modelo para produ√ß√£o\n",
    "\n",
    "### üèÜ Modelo que vamos testar\n",
    "- Random Forest (Ensemble)\n",
    "- KNN (K-Nearest Neighbors)\n",
    "- Logistic Regression (Linear)\n",
    "- Decision-Tree (Base do Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8953a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.12' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/ECOMMERCE/AppData/Local/Microsoft/WindowsApps/python3.13.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib  # Para salvar modelos\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# M√©tricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score,\n",
    "    roc_curve, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Configs de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"Set2\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando dados do SQLite\n",
    "DB_PATH = 'data/database.db'\n",
    "print(f\"\\nüìÇ Carregando dados: {DB_PATH}\")\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df = pd.read_sql(\"SELECT * FROM clientes\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b43975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificando vari√°veis categ√≥ricas\n",
    "print(\"üîÑ CODIFICANDO VARI√ÅVEIS CATEG√ìRICAS\")\n",
    "\n",
    "# Identifica\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'inadimplente' in cat_cols:\n",
    "  cat_cols.remove('inadimplente')\n",
    "\n",
    "print(f\"\\nüìù Vari√°veis categ√≥ricas: {cat_cols}\")\n",
    "\n",
    "# Codifica e salva encoders\n",
    "encoders = {}\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "for col in cat_cols:\n",
    "  encoder = LabelEncoder()\n",
    "  df[col] = encoder.fit_transform(df[col])\n",
    "  encoders[col] = encoder\n",
    "    \n",
    "  joblib.dump(encoder, f'../models/encoder_{col}.pkl')\n",
    "  print(f\"   ‚úÖ {col}: {list(encoder.classes_)}\")\n",
    "\n",
    "print(f\"\\nüíæ {len(encoders)} encoders salvos em ../models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8297c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara X e Y\n",
    "print(\"‚úÇÔ∏è SEPARANDO FEATURES (X) E TARGET (y)\")\n",
    "\n",
    "# Remove ID (coluna desnecess√°ria) e Target (Principal)\n",
    "X = df.drop(columns=['id_cliente', 'inadimplente'])\n",
    "y = df['inadimplente']\n",
    "\n",
    "print(f\"\\nüìä X: {X.shape} - {X.shape[1]} features\")\n",
    "print(f\"üìä y: {y.shape}\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95358239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir Treino/Teste\n",
    "print(\"üîÄ TREINO/TESTE (70/30)\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y,\n",
    "  test_size=0.3,\n",
    "  random_state=42,\n",
    "  stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Treino: {len(X_train):,} ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"‚úÖ Teste:  {len(X_test):,} ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "print(f\"\\nTaxa inadimpl√™ncia treino: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Taxa inadimpl√™ncia teste:  {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a58595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza√ß√£o (Para KNN e LR)\n",
    "print(\"‚öñÔ∏è NORMALIZA√á√ÉO (StandardScaler)\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Converte de volta para DataFrame\n",
    "X_train_scaled = pd.DataFrame(\n",
    "  X_train_scaled,\n",
    "  columns=X.columns,\n",
    "  index=X_train.index\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "  X_test_scaled,\n",
    "  columns=X.columns,\n",
    "  index=X_test.index\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Dados normalizados (m√©dia=0, std=1)\")\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print(\"üíæ Scaler salvo em ../models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2a655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar Modelos\n",
    "print(\"ü§ñ TREINANDO MODELOS\")\n",
    "\n",
    "modelos = {}\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# RANDOM FOREST\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\n1Ô∏è‚É£ Random Forest...\")\n",
    "modelo_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'  # IMPORTANTE: lida com desbalanceamento\n",
    ")\n",
    "modelo_rf.fit(X_train, y_train)\n",
    "modelos['Random Forest'] = modelo_rf\n",
    "print(\"‚úÖ Treinado (SEM normaliza√ß√£o)\")\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# LOGISTIC REGRESSION\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\n2Ô∏è‚É£ Logistic Regression...\")\n",
    "modelo_lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "modelos['Logistic Regression'] = modelo_lr\n",
    "print(\"‚úÖ Treinado (COM normaliza√ß√£o)\")\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# KNN (K-Nearest Neighbors)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\n3Ô∏è‚É£ KNN...\")\n",
    "modelo_knn = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    weights='distance',\n",
    "    n_jobs=-1\n",
    ")\n",
    "modelo_knn.fit(X_train_scaled, y_train)\n",
    "modelos['KNN'] = modelo_knn\n",
    "print(\"‚úÖ Treinado (COM normaliza√ß√£o)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f18399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previs√µes\n",
    "print(\"üîÆ FAZENDO PREVIS√ïES\")\n",
    "\n",
    "previsoes = {}\n",
    "probabilidades = {}\n",
    "\n",
    "# RF (sem normaliza√ß√£o)\n",
    "previsoes['Random Forest'] = modelo_rf.predict(X_test)\n",
    "probabilidades['Random Forest'] = modelo_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# LR (com normaliza√ß√£o)\n",
    "previsoes['Logistic Regression'] = modelo_lr.predict(X_test_scaled)\n",
    "probabilidades['Logistic Regression'] = modelo_lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# KNN (com normaliza√ß√£o)\n",
    "previsoes['KNN'] = modelo_knn.predict(X_test_scaled)\n",
    "probabilidades['KNN'] = modelo_knn.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b65938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar Modelos - M√âTRICAS COMPLETAS\n",
    "print(\"üìä AVALIA√á√ÉO DOS MODELOS\")\n",
    "\n",
    "\"\"\"\n",
    "IMPORTANTE: Em cr√©dito, RECALL √© mais importante que ACCURACY!\n",
    "\n",
    "Por qu√™?\n",
    "- Accuracy alta pode ser enganosa (prev√™ tudo como adimplente)\n",
    "- RECALL mede: \"dos inadimplentes reais, quantos detectamos?\"\n",
    "- Em cr√©dito, N√ÉO detectar inadimplente √© mais caro!\n",
    "\n",
    "M√©tricas priorizadas:\n",
    "1. Recall (classe inadimplente)\n",
    "2. AUC-ROC (performance geral)\n",
    "3. F1-Score (balan√ßo)\n",
    "\"\"\"\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for nome in modelos.keys():\n",
    "      y_pred = previsoes[nome]\n",
    "      y_prob = probabilidades[nome]\n",
    "    \n",
    "      # Calcula m√©tricas\n",
    "      acc = accuracy_score(y_test, y_pred)\n",
    "      prec = precision_score(y_test, y_pred)\n",
    "      rec = recall_score(y_test, y_pred)  # ‚Üê M√âTRICA PRINCIPAL\n",
    "      f1 = f1_score(y_test, y_pred)\n",
    "      auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "      resultados[nome] = {\n",
    "          'Accuracy': acc,\n",
    "          'Precision': prec,\n",
    "          'Recall': rec,  # ‚Üê PRIORIDADE\n",
    "          'F1-Score': f1,\n",
    "          'AUC-ROC': auc  # ‚Üê MUITO IMPORTANTE EM CR√âDITO\n",
    "      }\n",
    "    \n",
    "      print(f\"\\n{'‚ïê'*80}\")\n",
    "      print(f\"üìå {nome}\")\n",
    "      print(f\"{'‚ïê'*80}\")\n",
    "      print(f\"   Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "      print(f\"   Precision: {prec:.4f} ({prec*100:.2f}%)\")\n",
    "      print(f\"   Recall:    {rec:.4f} ({rec*100:.2f}%) ‚≠ê PRINCIPAL\")\n",
    "      print(f\"   F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "      print(f\"   AUC-ROC:   {auc:.4f} ({auc*100:.2f}%) ‚≠ê IMPORTANTE\")\n",
    "    \n",
    "      print(f\"\\nüí° Interpreta√ß√£o:\")\n",
    "      print(f\"‚Ä¢ Detecta {rec*100:.0f}% dos inadimplentes reais\")\n",
    "      print(f\"‚Ä¢ Quando aprova, {prec*100:.0f}% s√£o confi√°veis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c855fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melhor Modelo (POR RECALL)\n",
    "print(\"üèÜ SELE√á√ÉO DO MELHOR MODELO\")\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados).T\n",
    "\n",
    "# ORDENA POR RECALL\n",
    "df_resultados = df_resultados.sort_values('Recall', ascending=False)\n",
    "\n",
    "print(f\"\\n{df_resultados.to_string()}\")\n",
    "\n",
    "# Melhor modelo\n",
    "melhor_modelo = df_resultados.index[0]\n",
    "melhor_recall = df_resultados.iloc[0]['Recall']\n",
    "melhor_auc = df_resultados.iloc[0]['AUC-ROC']\n",
    "\n",
    "print(f\"\\nüèÜ MELHOR MODELO: {melhor_modelo}\")\n",
    "print(f\"Recall: {melhor_recall:.4f} ({melhor_recall*100:.2f}%)\")\n",
    "print(f\"AUC-ROC: {melhor_auc:.4f} ({melhor_auc*100:.2f}%)\")\n",
    "print(f\"\\nüí° Escolhido por RECALL (detectar inadimplentes √© prioridade!)\")\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Compara√ß√£o de Recall\n",
    "df_resultados['Recall'].plot(\n",
    "    kind='barh', ax=axes[0], color='coral', edgecolor='black'\n",
    ")\n",
    "axes[0].set_xlabel('Recall (Classe Inadimplente)', fontsize=12)\n",
    "axes[0].set_title('Compara√ß√£o de Recall - M√âTRICA PRINCIPAL', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "axes[0].set_xlim([0, 1])\n",
    "\n",
    "for i, v in enumerate(df_resultados['Recall']):\n",
    "    axes[0].text(v + 0.01, i, f'{v:.1%}', va='center')\n",
    "\n",
    "\n",
    "# Todas as m√©tricas\n",
    "df_resultados[['Recall', 'F1-Score', 'AUC-ROC', 'Precision']].plot(\n",
    "    kind='bar', ax=axes[1], alpha=0.8, edgecolor='black'\n",
    ")\n",
    "axes[1].set_ylabel('Score', fontsize=12)\n",
    "axes[1].set_title('Todas as M√©tricas por Modelo', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c47de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC e AUC (OBRIGAT√ìRIO EM CR√âDITO!)\n",
    "print(\"üìà CURVA ROC E AUC üëá\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "\"\"\"\n",
    "ROC (Receiver Operating Characteristic):\n",
    "- Mostra trade-off entre True Positive Rate e False Positive Rate\n",
    "- AUC (Area Under Curve): resumo em um n√∫mero (0.5 a 1.0)\n",
    "- AUC > 0.8: Excelente\n",
    "- AUC > 0.7: Bom\n",
    "- AUC > 0.6: Aceit√°vel\n",
    "- AUC = 0.5: Random (in√∫til)\n",
    "\n",
    "Vantagem: independe do threshold!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# ROC de todos os modelos\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "for nome in modelos.keys():\n",
    "    y_prob = probabilidades[nome]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    auc = resultados[nome]['AUC-ROC']\n",
    "    \n",
    "    axes[0].plot(fpr, tpr, linewidth=2, \n",
    "                label=f'{nome} (AUC = {auc:.3f})')\n",
    "    \n",
    "# Random\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random (AUC = 0.500)')\n",
    "\n",
    "axes[0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[0].set_title('Curva ROC - Compara√ß√£o de Modelos', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# ROC do MELHOR modelo (detalhado)\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "y_prob_best = probabilidades[melhor_modelo]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob_best)\n",
    "auc_best = resultados[melhor_modelo]['AUC-ROC']\n",
    "\n",
    "axes[1].plot(fpr, tpr, linewidth=3, color='red', \n",
    "            label=f'{melhor_modelo} (AUC = {auc_best:.3f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.5)\n",
    "axes[1].fill_between(fpr, tpr, alpha=0.2, color='red')\n",
    "\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title(f'Curva ROC - {melhor_modelo}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Adiciona ponto do threshold 0.5\n",
    "idx_05 = np.argmin(np.abs(thresholds - 0.5))\n",
    "axes[1].plot(fpr[idx_05], tpr[idx_05], 'go', markersize=10, \n",
    "            label=f'Threshold = 0.5')\n",
    "axes[1].legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä AUC (Area Under Curve):\")\n",
    "for nome, res in resultados.items():\n",
    "    auc = res['AUC-ROC']\n",
    "    if auc > 0.8:\n",
    "        nivel = \"üü¢ EXCELENTE\"\n",
    "    elif auc > 0.7:\n",
    "        nivel = \"üü° BOM\"\n",
    "    elif auc > 0.6:\n",
    "        nivel = \"üü† ACEIT√ÅVEL\"\n",
    "    else:\n",
    "        nivel = \"üî¥ FRACO\"\n",
    "    print(f\"{nome:25s}: {auc:.4f} {nivel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06572b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de Threshold\n",
    "print(\"üéöÔ∏è AN√ÅLISE DE THRESHOLD (DECIS√ÉO DE NEG√ìCIO)\")\n",
    "\n",
    "\"\"\"\n",
    "THRESHOLD = ponto de corte para classificar\n",
    "\n",
    "Threshold 0.5 (padr√£o):\n",
    "- Se prob > 0.5 ‚Üí Inadimplente\n",
    "- Se prob ‚â§ 0.5 ‚Üí Adimplente\n",
    "\n",
    "MAS em cr√©dito, threshold √© DECIS√ÉO DE NEG√ìCIO!\n",
    "\n",
    "Threshold BAIXO (0.3):\n",
    "‚úÖ Aprova mais clientes\n",
    "‚úÖ Mais receita\n",
    "‚ùå Mais risco\n",
    "\n",
    "Threshold ALTO (0.7):\n",
    "‚úÖ Menos risco\n",
    "‚úÖ Mais precision\n",
    "‚ùå Aprova menos (perde clientes bons)\n",
    "\"\"\"\n",
    "\n",
    "# Testa diferentes thresholds\n",
    "thresholds_teste = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "y_prob_best = probabilidades[melhor_modelo]\n",
    "\n",
    "resultados_threshold = []\n",
    "\n",
    "for threshold in thresholds_teste:\n",
    "    # Aplica threshold\n",
    "    y_pred_custom = (y_prob_best >= threshold).astype(int)\n",
    "    \n",
    "    # Calcula m√©tricas\n",
    "    prec = precision_score(y_test, y_pred_custom)\n",
    "    rec = recall_score(y_test, y_pred_custom)\n",
    "    f1 = f1_score(y_test, y_pred_custom)\n",
    "    \n",
    "    # Simula aprova√ß√£o\n",
    "    taxa_aprovacao = (y_pred_custom == 0).mean() * 100\n",
    "    \n",
    "    resultados_threshold.append({\n",
    "        'Threshold': threshold,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Taxa Aprova√ß√£o': taxa_aprovacao\n",
    "    })\n",
    "\n",
    "df_threshold = pd.DataFrame(resultados_threshold)\n",
    "print(f\"\\n{df_threshold.to_string(index=False)}\")\n",
    "\n",
    "print(f\"\\nüí° Interpreta√ß√£o:\")\n",
    "print(f\"‚Ä¢ Threshold 0.3: Aprova mais ({df_threshold.iloc[0]['Taxa Aprova√ß√£o']:.1f}%), mas mais risco\")\n",
    "print(f\"‚Ä¢ Threshold 0.5: Padr√£o ({df_threshold.iloc[2]['Taxa Aprova√ß√£o']:.1f}%)\")\n",
    "print(f\"‚Ä¢ Threshold 0.7: Mais conservador ({df_threshold.iloc[4]['Taxa Aprova√ß√£o']:.1f}%), menos risco\")\n",
    "\n",
    "# Visualiza√ß√£o\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# M√©tricas vs Threshold\n",
    "df_threshold.plot(x='Threshold', y=['Precision', 'Recall', 'F1-Score'],\n",
    "                 ax=axes[0], marker='o', linewidth=2, markersize=8)\n",
    "axes[0].set_ylabel('Score', fontsize=12)\n",
    "axes[0].set_title('M√©tricas vs Threshold', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].legend(loc='best')\n",
    "axes[0].set_ylim([0, 1])\n",
    "\n",
    "# Taxa de Aprova√ß√£o vs Threshold\n",
    "axes[1].plot(df_threshold['Threshold'], df_threshold['Taxa Aprova√ß√£o'],\n",
    "            marker='o', linewidth=2, markersize=8, color='green')\n",
    "axes[1].set_xlabel('Threshold', fontsize=12)\n",
    "axes[1].set_ylabel('Taxa de Aprova√ß√£o (%)', fontsize=12)\n",
    "axes[1].set_title('Taxa de Aprova√ß√£o vs Threshold', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].fill_between(df_threshold['Threshold'], df_threshold['Taxa Aprova√ß√£o'], \n",
    "                     alpha=0.2, color='green')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf5ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confus√£o\n",
    "print(\"üéØ MATRIZ DE CONFUS√ÉO\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, nome in enumerate(modelos.keys()):\n",
    "    cm = confusion_matrix(y_test, previsoes[nome])\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm,\n",
    "        display_labels=['Adimplente', 'Inadimplente']\n",
    "    )\n",
    "    disp.plot(ax=axes[idx], cmap='Blues', values_format='d', colorbar=False)\n",
    "    \n",
    "    recall = resultados[nome]['Recall']\n",
    "    axes[idx].set_title(f'{nome}\\nRecall: {recall:.2%}', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Matriz do melhor modelo (DETALHADA!)\n",
    "cm_best = confusion_matrix(y_test, previsoes[melhor_modelo])\n",
    "print(f\"\\nüìå Matriz de Confus√£o - {melhor_modelo}:\")\n",
    "print(f\"{'‚îÄ'*60}\")\n",
    "print(f\"VN (Verdadeiro Negativo):  {cm_best[0,0]:>6,} ‚Üê Previu adimpl√™ncia e era\")\n",
    "print(f\"FP (Falso Positivo):       {cm_best[0,1]:>6,} ‚Üê Previu inadimpl√™ncia mas era adiml√™ncia\")\n",
    "print(f\"FN (Falso Negativo):       {cm_best[1,0]:>6,} ‚Üê Previu adimpl√™ncia mas era inadimpl√™ncia ‚ö†Ô∏è\")\n",
    "print(f\"VP (Verdadeiro Positivo):  {cm_best[1,1]:>6,} ‚Üê Previu inadimpl√™ncia e era ‚úÖ\")\n",
    "\n",
    "# Aten√ß√£o especial ao Falso Negativo (FN), pois representa clientes inadimplentes classificados como adimplentes ‚Äî erro de alto custo financeiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "print(\"üîÑ CROSS-VALIDATION (5-FOLD)\")\n",
    "\n",
    "# CV apenas no melhor modelo para economizar tempo\n",
    "modelo_cv = modelos[melhor_modelo]\n",
    "\n",
    "if melhor_modelo == 'Logistic Regression':\n",
    "    X_cv = X_train_scaled\n",
    "else:\n",
    "    X_cv = X_train\n",
    "\n",
    "print(f\"\\n‚è≥ Validando {melhor_modelo}...\")\n",
    "\n",
    "# CV com 5 folds\n",
    "scores_recall = cross_val_score(modelo_cv, X_cv, y_train, \n",
    "                                cv=5, scoring='recall')\n",
    "scores_auc = cross_val_score(modelo_cv, X_cv, y_train, \n",
    "                             cv=5, scoring='roc_auc')\n",
    "\n",
    "print(f\"\\nüìä Recall (5 folds): {[f'{s:.4f}' for s in scores_recall]}\")\n",
    "print(f\"M√©dia: {scores_recall.mean():.4f} ¬± {scores_recall.std():.4f}\")\n",
    "\n",
    "print(f\"\\nüìä AUC-ROC (5 folds): {[f'{s:.4f}' for s in scores_auc]}\")\n",
    "print(f\"M√©dia: {scores_auc.mean():.4f} ¬± {scores_auc.std():.4f}\")\n",
    "\n",
    "# Considera o modelo est√°vel se o desvio padr√£o do Recall\n",
    "# e do AUC-ROC entre os folds for menor que 3%\n",
    "if scores_recall.std() < 0.03 and scores_auc.std() < 0.03:\n",
    "    print(\"\\n‚úÖ Modelo est√°vel (baixa varia√ß√£o entre folds)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Modelo apresenta varia√ß√£o relevante entre folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eb57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "print(\"‚≠ê FEATURE IMPORTANCE\")\n",
    "\n",
    "if melhor_modelo == 'Random Forest':\n",
    "    importancias = modelo_rf.feature_importances_\n",
    "\n",
    "    df_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Import√¢ncia': importancias}).sort_values('Import√¢ncia', ascending=False)\n",
    "    \n",
    "    print(f\"\\nüèÜ TOP 10 FEATURES:\")\n",
    "    print(f\"{'‚îÄ'*60}\")\n",
    "    for i, row in df_importance.head(10).iterrows():\n",
    "        print(f\"{row['Feature']:30s}: {row['Import√¢ncia']:.4f}\")    \n",
    "\n",
    "    # Visualiza√ß√£o\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Top 15 ( oferece bom equil√≠brio entre legibilidade e cobertura da import√¢ncia total)\n",
    "    top_n = 15\n",
    "    df_top = df_importance.head(top_n)\n",
    "    colors = plt.cm.viridis(np.linspace(0.2, 0.9, len(df_top)))\n",
    "    \n",
    "    axes[0].barh(range(len(df_top)), df_top['Import√¢ncia'], color=colors)\n",
    "    axes[0].set_yticks(range(len(df_top)))\n",
    "    axes[0].set_yticklabels(df_top['Feature'])\n",
    "    axes[0].set_xlabel('Import√¢ncia', fontsize=12)\n",
    "    axes[0].set_title(f'Top {top_n} Features Mais Importantes', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    axes[0].invert_yaxis()\n",
    "    axes[0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Import√¢ncia acumulada\n",
    "    df_importance['Acumulado'] = df_importance['Import√¢ncia'].cumsum()\n",
    "    axes[1].plot(range(1, len(df_importance)+1), \n",
    "                df_importance['Acumulado']*100, \n",
    "                marker='o', linewidth=2, markersize=4)\n",
    "    axes[1].axhline(80, color='red', linestyle='--', label='80%')\n",
    "    axes[1].set_xlabel('N√∫mero de Features', fontsize=12)\n",
    "    axes[1].set_ylabel('Import√¢ncia Acumulada (%)', fontsize=12)\n",
    "    axes[1].set_title('Import√¢ncia Acumulada', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Salva rela√ß√£o\n",
    "    df_importance.to_csv('data/feature_importance.csv', index=False)\n",
    "    print(f\"\\nüíæ Salvo: data/feature_importance.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
